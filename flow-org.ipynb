{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mig2005 = pd.read_excel('migration_flows_2005.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last 3 rows\n",
    "mig2005 = mig2005.iloc[:-3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns that contain 'MOE' as a value\n",
    "moe_columns = [col for col in mig2005.columns if mig2005[col].astype(str).str.contains('MOE').any()]\n",
    "\n",
    "# Drop those columns\n",
    "mig2005 = mig2005.drop(columns=moe_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first 5 rows\n",
    "mig2005 = mig2005.iloc[5:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all values are missing\n",
    "mig2005 = mig2005.dropna(how='all')\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "mig2005 = mig2005.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows 2 and 33-35\n",
    "mig2005 = mig2005.drop(index=[1, 32, 33, 34])\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "mig2005 = mig2005.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the first row first column equal to 0\n",
    "mig2005.iloc[0, 0] = 0\n",
    "\n",
    "# Set the first column as the index\n",
    "mig2005 = mig2005.set_index(mig2005.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns where the first row has missing values\n",
    "mig2005 = mig2005.loc[:, mig2005.iloc[0].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = mig2005.iloc[0].values\n",
    "\n",
    "data = []\n",
    "for i in range(1, len(mig2005)):\n",
    "    for j in range(len(mig2005.columns)):\n",
    "        if mig2005.iloc[i, j] != '':\n",
    "            data.append({\n",
    "                'Origin': states[j],\n",
    "                'Direction': mig2005.index[i],\n",
    "                'Year': 2005,\n",
    "                'Population Change': mig2005.iloc[i, j]\n",
    "            })\n",
    "flows_05 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 Excel files: ['migration_flows_2005.xls', 'migration_flows_2006.xls', 'migration_flows_2007.xls', 'migration_flows_2008.xls', 'migration_flows_2009.xls', 'migration_flows_2010.xls', 'migration_flows_2011.xls', 'migration_flows_2012.xls', 'migration_flows_2013.xls', 'migration_flows_2014.xls', 'migration_flows_2015.xls', 'migration_flows_2016.xls', 'migration_flows_2017.xls', 'migration_flows_2021.xls', 'migration_flows_2022.xlsx', 'migration_flows_2023.xlsx', '~$migration_flows_2023.xlsx']\n",
      "Processing file: migration_flows_2005.xls\n",
      "Extracted year: 2005\n",
      "Successfully processed migration_flows_2005.xls, created 2704 rows\n",
      "Processing file: migration_flows_2006.xls\n",
      "Extracted year: 2006\n",
      "Successfully processed migration_flows_2006.xls, created 2704 rows\n",
      "Processing file: migration_flows_2007.xls\n",
      "Extracted year: 2007\n",
      "Successfully processed migration_flows_2007.xls, created 2704 rows\n",
      "Processing file: migration_flows_2008.xls\n",
      "Extracted year: 2008\n",
      "Successfully processed migration_flows_2008.xls, created 2704 rows\n",
      "Processing file: migration_flows_2009.xls\n",
      "Extracted year: 2009\n",
      "Successfully processed migration_flows_2009.xls, created 2704 rows\n",
      "Processing file: migration_flows_2010.xls\n",
      "Extracted year: 2010\n",
      "Successfully processed migration_flows_2010.xls, created 2875 rows\n",
      "Processing file: migration_flows_2011.xls\n",
      "Extracted year: 2011\n",
      "Successfully processed migration_flows_2011.xls, created 2875 rows\n",
      "Processing file: migration_flows_2012.xls\n",
      "Extracted year: 2012\n",
      "Successfully processed migration_flows_2012.xls, created 2875 rows\n",
      "Processing file: migration_flows_2013.xls\n",
      "Extracted year: 2013\n",
      "Successfully processed migration_flows_2013.xls, created 2875 rows\n",
      "Processing file: migration_flows_2014.xls\n",
      "Extracted year: 2014\n",
      "Successfully processed migration_flows_2014.xls, created 2875 rows\n",
      "Processing file: migration_flows_2015.xls\n",
      "Extracted year: 2015\n",
      "Successfully processed migration_flows_2015.xls, created 2875 rows\n",
      "Processing file: migration_flows_2016.xls\n",
      "Extracted year: 2016\n",
      "Successfully processed migration_flows_2016.xls, created 2874 rows\n",
      "Processing file: migration_flows_2017.xls\n",
      "Extracted year: 2017\n",
      "Successfully processed migration_flows_2017.xls, created 2874 rows\n",
      "Processing file: migration_flows_2021.xls\n",
      "Extracted year: 2021\n",
      "Successfully processed migration_flows_2021.xls, created 2874 rows\n",
      "Processing file: migration_flows_2022.xlsx\n",
      "Extracted year: 2022\n",
      "Successfully processed migration_flows_2022.xlsx, created 2874 rows\n",
      "Processing file: migration_flows_2023.xlsx\n",
      "Extracted year: 2023\n",
      "Successfully processed migration_flows_2023.xlsx, created 2751 rows\n",
      "Processing file: ~$migration_flows_2023.xlsx\n",
      "Error processing ~$migration_flows_2023.xlsx: [Errno 2] No such file or directory: 'C:\\\\Users\\\\$migration_flows_2023.xlsx'\n",
      "Created combined dataset with 45017 rows\n",
      "Saved results to migration_flows_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# For 2005-2009\n",
    "def process_migration_file(file_path):\n",
    "    try:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Get the year from the filename\n",
    "        year = int(file_path.split('_')[-1].split('.')[0])\n",
    "        print(f\"Extracted year: {year}\")\n",
    "        \n",
    "        # Drop the last 3 rows\n",
    "        df = df.iloc[:-3].reset_index(drop=True)\n",
    "        \n",
    "        # Find and drop MOE columns\n",
    "        moe_columns = [col for col in df.columns if df[col].astype(str).str.contains('MOE').any()]\n",
    "        df = df.drop(columns=moe_columns)\n",
    "        \n",
    "        # Drop the first 5 rows\n",
    "        df = df.iloc[5:].reset_index(drop=True)\n",
    "        \n",
    "        # Drop rows where all values are missing\n",
    "        df = df.dropna(how='all').reset_index(drop=True)\n",
    "        \n",
    "        try:\n",
    "            # Drop specific rows (2 and 33-35)\n",
    "            df = df.drop(index=[1, 32, 33, 34]).reset_index(drop=True)\n",
    "        except KeyError as e:\n",
    "            print(f\"Warning: Some indices not found in {file_path}, continuing...\")\n",
    "        \n",
    "        # Make the first row first column equal to 0\n",
    "        df.iloc[0, 0] = 0\n",
    "        \n",
    "        # Set the first column as the index\n",
    "        df = df.set_index(df.columns[0])\n",
    "        \n",
    "        # Drop columns where the first row has missing values\n",
    "        df = df.loc[:, df.iloc[0].notna()]\n",
    "        \n",
    "        # Create flows dataframe\n",
    "        states = df.iloc[0].values\n",
    "        data = []\n",
    "        for i in range(1, len(df)):\n",
    "            for j in range(len(df.columns)):\n",
    "                if pd.notna(df.iloc[i, j]) and df.iloc[i, j] != '':\n",
    "                    data.append({\n",
    "                        'Origin': states[j],\n",
    "                        'Direction': df.index[i],\n",
    "                        'Year': year,\n",
    "                        'Population Change': df.iloc[i, j]\n",
    "                    })\n",
    "        \n",
    "        result_df = pd.DataFrame(data)\n",
    "        print(f\"Successfully processed {file_path}, created {len(result_df)} rows\")\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Get all Excel files in the directory\n",
    "excel_files = glob.glob('*.xls*')\n",
    "print(f\"Found {len(excel_files)} Excel files: {excel_files}\")\n",
    "\n",
    "# Process all files and store results in a list\n",
    "all_flows = []\n",
    "for file in excel_files:\n",
    "    flows = process_migration_file(file)\n",
    "    if flows is not None:\n",
    "        all_flows.append(flows)\n",
    "\n",
    "# Check if we have any processed data\n",
    "if len(all_flows) > 0:\n",
    "    # Combine all flows into one dataframe\n",
    "    combined_flows = pd.concat(all_flows, ignore_index=True)\n",
    "    print(f\"Created combined dataset with {len(combined_flows)} rows\")\n",
    "    \n",
    "    # Save the combined results\n",
    "    combined_flows.to_csv('migration_flows_combined.csv', index=False)\n",
    "    print(\"Saved results to migration_flows_combined.csv\")\n",
    "else:\n",
    "    print(\"No files were successfully processed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mig2010 = pd.read_excel('migration_flows_2010.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mig2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last 8 rows\n",
    "mig2010 = mig2010.iloc[:-8].reset_index(drop=True)\n",
    "\n",
    "# Find columns that contain 'MOE' as a value\n",
    "moe_columns = [col for col in mig2010.columns if mig2010[col].astype(str).str.contains('MOE').any()]\n",
    "\n",
    "# Drop those columns\n",
    "mig2010 = mig2010.drop(columns=moe_columns)\n",
    "\n",
    "# Drop rows where all values are missing\n",
    "mig2010 = mig2010.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Delete the second and third columns\n",
    "mig2010 = mig2010.drop(mig2010.columns[[1, 2]], axis=1)\n",
    "\n",
    "mig2010.iloc[0,0] = 0\n",
    "\n",
    "# Find columns that contain 'Table 1' as a value\n",
    "extra_columns = [col for col in mig2010.columns if mig2010[col].astype(str).str.contains('Table 1').any()]\n",
    "\n",
    "# Drop those columns\n",
    "mig2010 = mig2010.drop(columns=extra_columns)\n",
    "\n",
    "# Drop the third column\n",
    "mig2010 = mig2010.drop(mig2010.columns[2], axis=1)\n",
    "\n",
    "# Drop first four rows\n",
    "mig2010 = mig2010.iloc[4:].reset_index(drop=True)\n",
    "\n",
    "mig2010.iloc[0,1] = 'Stayed'\n",
    "\n",
    "# Delete rows 1, 2, 30, 31, 32\n",
    "mig2010 = mig2010.drop(index=[1, 2, 30, 31, 32]).reset_index(drop=True)\n",
    "\n",
    "mig2010.iloc[0,0] = \"Origin\"\n",
    "\n",
    "# Make the first row the column names\n",
    "mig2010.columns = mig2010.iloc[0]\n",
    "\n",
    "# Delete the first row\n",
    "mig2010 = mig2010.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# Replace missing values where Origin matches column name with values from 'Stayed' column\n",
    "for col in mig2010.columns:\n",
    "    # Find the row where Origin equals the column name\n",
    "    matching_row = mig2010[mig2010['Origin'] == col]\n",
    "    if not matching_row.empty:\n",
    "        # Get the 'Stayed' value for this state\n",
    "        stayed_value = matching_row['Stayed'].values[0]\n",
    "        # Replace the missing value in the corresponding column\n",
    "        mig2010.loc[mig2010['Origin'] == col, col] = stayed_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 Excel files: ['migration_flows_2005.xls', 'migration_flows_2006.xls', 'migration_flows_2007.xls', 'migration_flows_2008.xls', 'migration_flows_2009.xls', 'migration_flows_2010.xls', 'migration_flows_2011.xls', 'migration_flows_2012.xls', 'migration_flows_2013.xls', 'migration_flows_2014.xls', 'migration_flows_2015.xls', 'migration_flows_2016.xls', 'migration_flows_2017.xls', 'migration_flows_2021.xls', 'migration_flows_2022.xlsx', 'migration_flows_2023.xlsx', '~$migration_flows_2023.xlsx']\n",
      "Processing file: migration_flows_2005.xls\n",
      "Extracted year: 2005\n",
      "Successfully processed migration_flows_2005.xls, created 2756 rows\n",
      "Processing file: migration_flows_2006.xls\n",
      "Extracted year: 2006\n",
      "Successfully processed migration_flows_2006.xls, created 2756 rows\n",
      "Processing file: migration_flows_2007.xls\n",
      "Extracted year: 2007\n",
      "Successfully processed migration_flows_2007.xls, created 2756 rows\n",
      "Processing file: migration_flows_2008.xls\n",
      "Extracted year: 2008\n",
      "Successfully processed migration_flows_2008.xls, created 2756 rows\n",
      "Processing file: migration_flows_2009.xls\n",
      "Extracted year: 2009\n",
      "Successfully processed migration_flows_2009.xls, created 2756 rows\n",
      "Processing file: migration_flows_2010.xls\n",
      "Extracted year: 2010\n",
      "Error processing migration_flows_2010.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2011.xls\n",
      "Extracted year: 2011\n",
      "Error processing migration_flows_2011.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2012.xls\n",
      "Extracted year: 2012\n",
      "Error processing migration_flows_2012.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2013.xls\n",
      "Extracted year: 2013\n",
      "Error processing migration_flows_2013.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2014.xls\n",
      "Extracted year: 2014\n",
      "Error processing migration_flows_2014.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2015.xls\n",
      "Extracted year: 2015\n",
      "Error processing migration_flows_2015.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2016.xls\n",
      "Extracted year: 2016\n",
      "Error processing migration_flows_2016.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2017.xls\n",
      "Extracted year: 2017\n",
      "Error processing migration_flows_2017.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2021.xls\n",
      "Extracted year: 2021\n",
      "Error processing migration_flows_2021.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2022.xlsx\n",
      "Extracted year: 2022\n",
      "Error processing migration_flows_2022.xlsx: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2023.xlsx\n",
      "Extracted year: 2023\n",
      "Successfully processed migration_flows_2023.xlsx, created 2646 rows\n",
      "Processing file: ~$migration_flows_2023.xlsx\n",
      "Error processing ~$migration_flows_2023.xlsx: [Errno 2] No such file or directory: 'C:\\\\Users\\\\$migration_flows_2023.xlsx'\n",
      "Created combined dataset with 16426 rows\n",
      "Saved results to migration_flows_combined.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Year</th>\n",
       "      <th>Population Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16195</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16196</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16198</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2023</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16199</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16200</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>2023</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16201</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16202</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2023</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16203</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2023</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16204</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Utah</td>\n",
       "      <td>2023</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16205</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16206</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>2023</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16207</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2023</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16208</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16209</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2023</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16210</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16211</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Total</td>\n",
       "      <td>2023</td>\n",
       "      <td>4338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16212</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2023</td>\n",
       "      <td>155228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16213</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>U.S. Island Area3</td>\n",
       "      <td>2023</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Foreign Country</td>\n",
       "      <td>2023</td>\n",
       "      <td>4275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Origin          Direction  Year  Population Change\n",
       "16195  Puerto Rico               Ohio  2023                  0\n",
       "16196  Puerto Rico           Oklahoma  2023                  0\n",
       "16197  Puerto Rico             Oregon  2023                  0\n",
       "16198  Puerto Rico       Pennsylvania  2023               3040\n",
       "16199  Puerto Rico       Rhode Island  2023                  0\n",
       "16200  Puerto Rico     South Carolina  2023                314\n",
       "16201  Puerto Rico       South Dakota  2023                  0\n",
       "16202  Puerto Rico          Tennessee  2023                293\n",
       "16203  Puerto Rico              Texas  2023               2252\n",
       "16204  Puerto Rico               Utah  2023                 37\n",
       "16205  Puerto Rico            Vermont  2023                  0\n",
       "16206  Puerto Rico           Virginia  2023                443\n",
       "16207  Puerto Rico         Washington  2023                519\n",
       "16208  Puerto Rico      West Virginia  2023                  0\n",
       "16209  Puerto Rico          Wisconsin  2023                505\n",
       "16210  Puerto Rico            Wyoming  2023                  0\n",
       "16211  Puerto Rico              Total  2023               4338\n",
       "16212  Puerto Rico        Puerto Rico  2023             155228\n",
       "16213  Puerto Rico  U.S. Island Area3  2023                 63\n",
       "16214  Puerto Rico    Foreign Country  2023               4275"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_flows = pd.read_csv('migration_flows_combined.csv')\n",
    "\n",
    "\n",
    "#combined_flows.head()\n",
    "\n",
    "combined_flows.tail(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 Excel files: ['migration_flows_2005.xls', 'migration_flows_2006.xls', 'migration_flows_2007.xls', 'migration_flows_2008.xls', 'migration_flows_2009.xls', 'migration_flows_2010.xls', 'migration_flows_2011.xls', 'migration_flows_2012.xls', 'migration_flows_2013.xls', 'migration_flows_2014.xls', 'migration_flows_2015.xls', 'migration_flows_2016.xls', 'migration_flows_2017.xls', 'migration_flows_2021.xls', 'migration_flows_2022.xlsx', 'migration_flows_2023.xlsx', '~$migration_flows_2023.xlsx']\n",
      "Processing file: migration_flows_2005.xls\n",
      "Extracted year: 2005\n",
      "Successfully processed migration_flows_2005.xls, created 2704 rows\n",
      "Processing file: migration_flows_2006.xls\n",
      "Extracted year: 2006\n",
      "Successfully processed migration_flows_2006.xls, created 2704 rows\n",
      "Processing file: migration_flows_2007.xls\n",
      "Extracted year: 2007\n",
      "Successfully processed migration_flows_2007.xls, created 2704 rows\n",
      "Processing file: migration_flows_2008.xls\n",
      "Extracted year: 2008\n",
      "Successfully processed migration_flows_2008.xls, created 2704 rows\n",
      "Processing file: migration_flows_2009.xls\n",
      "Extracted year: 2009\n",
      "Successfully processed migration_flows_2009.xls, created 2704 rows\n",
      "Processing file: migration_flows_2010.xls\n",
      "Extracted year: 2010\n",
      "Error processing migration_flows_2010.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2011.xls\n",
      "Extracted year: 2011\n",
      "Error processing migration_flows_2011.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2012.xls\n",
      "Extracted year: 2012\n",
      "Error processing migration_flows_2012.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2013.xls\n",
      "Extracted year: 2013\n",
      "Error processing migration_flows_2013.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2014.xls\n",
      "Extracted year: 2014\n",
      "Error processing migration_flows_2014.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2015.xls\n",
      "Extracted year: 2015\n",
      "Error processing migration_flows_2015.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2016.xls\n",
      "Extracted year: 2016\n",
      "Error processing migration_flows_2016.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2017.xls\n",
      "Extracted year: 2017\n",
      "Error processing migration_flows_2017.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2021.xls\n",
      "Extracted year: 2021\n",
      "Error processing migration_flows_2021.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2022.xlsx\n",
      "Extracted year: 2022\n",
      "Error processing migration_flows_2022.xlsx: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2023.xlsx\n",
      "Extracted year: 2023\n",
      "Successfully processed migration_flows_2023.xlsx, created 2695 rows\n",
      "Created combined dataset with 16215 rows\n",
      "Saved results to migration_flows_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_migration_file(file_path):\n",
    "    try:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Get the year from the filename\n",
    "        year = int(file_path.split('_')[-1].split('.')[0])\n",
    "        print(f\"Extracted year: {year}\")\n",
    "        \n",
    "        if year >= 2010:\n",
    "            # Process 2010 and later files\n",
    "            # Drop the last 8 rows\n",
    "            df = df.iloc[:-8].reset_index(drop=True)\n",
    "            \n",
    "            # Find and drop MOE columns\n",
    "            moe_columns = []\n",
    "            for col in df.columns:\n",
    "                if df[col].astype(str).str.contains('MOE').any():\n",
    "                    moe_columns.append(col)\n",
    "            df = df.drop(columns=moe_columns)\n",
    "            \n",
    "            # Drop rows where all values are missing\n",
    "            df = df.dropna(how='all').reset_index(drop=True)\n",
    "            \n",
    "            # Delete the second and third columns\n",
    "            df = df.drop(df.columns[[1, 2]], axis=1)\n",
    "           \n",
    "            \n",
    "            # Drop the third column if it exists\n",
    "            if len(df.columns) > 2:\n",
    "                df = df.drop(df.columns[2], axis=1)\n",
    "            \n",
    "            # Drop first four rows\n",
    "            df = df.iloc[4:].reset_index(drop=True)\n",
    "            \n",
    "            df.iloc[0,1] = 'Stayed'\n",
    "            \n",
    "            # Delete specific rows\n",
    "            df = df.drop(index=[1, 2, 30, 31, 32]).reset_index(drop=True)\n",
    "            \n",
    "            df.iloc[0,0] = \"Origin\"\n",
    "            \n",
    "            # Make the first row the column names\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.iloc[1:].reset_index(drop=True)\n",
    "            \n",
    "            # Replace missing values where Origin matches column name with values from 'Stayed' column\n",
    "            for col in df.columns:\n",
    "                if col in ['Origin', 'Stayed']:\n",
    "                    continue\n",
    "                # Find the row where Origin equals the column name\n",
    "                matching_rows = df[df['Origin'].astype(str) == str(col)]\n",
    "                if not matching_rows.empty:\n",
    "                    # Get the 'Stayed' value for this state\n",
    "                    stayed_value = matching_rows['Stayed'].values[0]\n",
    "                    # Replace the missing value in the corresponding column\n",
    "                    df.loc[df['Origin'].astype(str) == str(col), col] = stayed_value\n",
    "            \n",
    "            # Delete the 'Stayed' column\n",
    "            df = df.drop(columns=['Stayed'])\n",
    "            \n",
    "            # Create flows dataframe for 2010+ files\n",
    "            data = []\n",
    "            for idx, row in df.iterrows():\n",
    "                origin = row['Origin']\n",
    "                for col in df.columns:\n",
    "                    if col != 'Origin' and pd.notna(row[col]) and str(row[col]).strip() != '':\n",
    "                        data.append({\n",
    "                            'Origin': origin,\n",
    "                            'Direction': col,\n",
    "                            'Year': year,\n",
    "                            'Population Change': row[col]\n",
    "                        })\n",
    "            \n",
    "        else:\n",
    "            # Process pre-2010 files using original method\n",
    "            # Drop the last 3 rows\n",
    "            df = df.iloc[:-3].reset_index(drop=True)\n",
    "            \n",
    "            # Find and drop MOE columns\n",
    "            moe_columns = []\n",
    "            for col in df.columns:\n",
    "                if df[col].astype(str).str.contains('MOE').any():\n",
    "                    moe_columns.append(col)\n",
    "            df = df.drop(columns=moe_columns)\n",
    "            \n",
    "            # Drop the first 5 rows\n",
    "            df = df.iloc[5:].reset_index(drop=True)\n",
    "            \n",
    "            # Drop rows where all values are missing\n",
    "            df = df.dropna(how='all').reset_index(drop=True)\n",
    "            \n",
    "            try:\n",
    "                # Drop specific rows (2 and 33-35)\n",
    "                df = df.drop(index=[1, 32, 33, 34]).reset_index(drop=True)\n",
    "            except KeyError as e:\n",
    "                print(f\"Warning: Some indices not found in {file_path}, continuing...\")\n",
    "            \n",
    "            # Make the first row first column equal to 0\n",
    "            df.iloc[0, 0] = 0\n",
    "            \n",
    "            # Set the first column as the index\n",
    "            df = df.set_index(df.columns[0])\n",
    "            \n",
    "            # Drop columns where the first row has missing values\n",
    "            df = df.loc[:, df.iloc[0].notna()]\n",
    "            \n",
    "            # Create flows dataframe for pre-2010 files\n",
    "            states = df.iloc[0].values\n",
    "            data = []\n",
    "            for i in range(1, len(df)):\n",
    "                for j in range(len(df.columns)):\n",
    "                    if pd.notna(df.iloc[i, j]) and str(df.iloc[i, j]).strip() != '':\n",
    "                        data.append({\n",
    "                            'Origin': states[j],\n",
    "                            'Direction': df.index[i],\n",
    "                            'Year': year,\n",
    "                            'Population Change': df.iloc[i, j]\n",
    "                        })\n",
    "        \n",
    "        result_df = pd.DataFrame(data)\n",
    "        print(f\"Successfully processed {file_path}, created {len(result_df)} rows\")\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Get all Excel files in the directory\n",
    "excel_files = glob.glob('*.xls*')\n",
    "print(f\"Found {len(excel_files)} Excel files: {excel_files}\")\n",
    "\n",
    "# Process all files and store results in a list\n",
    "all_flows = []\n",
    "for file in excel_files:\n",
    "    if not file.startswith('~$'):  # Skip temporary Excel files\n",
    "        flows = process_migration_file(file)\n",
    "        if flows is not None:\n",
    "            all_flows.append(flows)\n",
    "\n",
    "# Check if we have any processed data\n",
    "if len(all_flows) > 0:\n",
    "    # Combine all flows into one dataframe\n",
    "    combined_flows = pd.concat(all_flows, ignore_index=True)\n",
    "    print(f\"Created combined dataset with {len(combined_flows)} rows\")\n",
    "    \n",
    "    # Save the combined results\n",
    "    combined_flows.to_csv('migration_flows_combined.csv', index=False)\n",
    "    print(\"Saved results to migration_flows_combined.csv\")\n",
    "else:\n",
    "    print(\"No files were successfully processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel('migration_flows_2010.xls')\n",
    "\n",
    "df = df.iloc[:-8].reset_index(drop=True)\n",
    "            \n",
    "            # Find and drop MOE columns\n",
    "moe_columns = [col for col in df.columns if df[col].astype(str).str.contains('MOE').any()]\n",
    "df = df.drop(columns=moe_columns)\n",
    "            \n",
    "            # Drop rows where all values are missing\n",
    "df = df.dropna(how='all').reset_index(drop=True)\n",
    "            \n",
    "            # Delete the second and third columns\n",
    "#df = df.drop(df.columns[[1, 2]], axis=1)\n",
    "            \n",
    "            # Find columns that contain 'Table 1' as a value\n",
    "#extra_columns = [col for col in df.columns if df[col].astype(str).str.contains('Table 1').any()]\n",
    "#df = df.drop(columns=extra_columns)\n",
    "            \n",
    "           \n",
    "            # Drop first four rows\n",
    "df = df.iloc[4:].reset_index(drop=True)\n",
    "            \n",
    "df.iloc[0,1] = 'Stayed'\n",
    "            \n",
    "            # Delete specific rows\n",
    "df = df.drop(index=[1, 2, 30, 31, 32]).reset_index(drop=True)\n",
    "            \n",
    "df.iloc[0,0] = \"Origin\"\n",
    "            \n",
    "            # Make the first row the column names\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:].reset_index(drop=True)\n",
    "            \n",
    "            # Replace missing values where Origin matches column name with values from 'Stayed' column\n",
    "for col in df.columns:\n",
    "    if col in ['Origin', 'Stayed']:\n",
    "        continue\n",
    "                # Find the row where Origin equals the column name\n",
    "    matching_row = df[df['Origin'] == col]\n",
    "    if not matching_row.empty:\n",
    "                    # Get the 'Stayed' value for this state\n",
    "            stayed_value = matching_row['Stayed'].values[0]\n",
    "                    # Replace the missing value in the corresponding column\n",
    "            df.loc[df['Origin'] == col, col] = stayed_value\n",
    "\n",
    "            # Delete the 'Stayed' column\n",
    "df = df.drop(columns=['Stayed'])\n",
    "\n",
    "#Delete columns titled nan\n",
    "df = df.drop(columns=[col for col in df.columns if 'nan' in str(col)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 Excel files: ['migration_flows_2005.xls', 'migration_flows_2006.xls', 'migration_flows_2007.xls', 'migration_flows_2008.xls', 'migration_flows_2009.xls', 'migration_flows_2010.xls', 'migration_flows_2011.xls', 'migration_flows_2012.xls', 'migration_flows_2013.xls', 'migration_flows_2014.xls', 'migration_flows_2015.xls', 'migration_flows_2016.xls', 'migration_flows_2017.xls', 'migration_flows_2021.xls', 'migration_flows_2022.xlsx', 'migration_flows_2023.xlsx', '~$migration_flows_2023.xlsx']\n",
      "Processing file: migration_flows_2005.xls\n",
      "Extracted year: 2005\n",
      "Successfully processed migration_flows_2005.xls, created 2704 rows\n",
      "Processing file: migration_flows_2006.xls\n",
      "Extracted year: 2006\n",
      "Successfully processed migration_flows_2006.xls, created 2704 rows\n",
      "Processing file: migration_flows_2007.xls\n",
      "Extracted year: 2007\n",
      "Successfully processed migration_flows_2007.xls, created 2704 rows\n",
      "Processing file: migration_flows_2008.xls\n",
      "Extracted year: 2008\n",
      "Successfully processed migration_flows_2008.xls, created 2704 rows\n",
      "Processing file: migration_flows_2009.xls\n",
      "Extracted year: 2009\n",
      "Successfully processed migration_flows_2009.xls, created 2704 rows\n",
      "Processing file: migration_flows_2010.xls\n",
      "Extracted year: 2010\n",
      "Error processing migration_flows_2010.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2011.xls\n",
      "Extracted year: 2011\n",
      "Error processing migration_flows_2011.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2012.xls\n",
      "Extracted year: 2012\n",
      "Error processing migration_flows_2012.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2013.xls\n",
      "Extracted year: 2013\n",
      "Error processing migration_flows_2013.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2014.xls\n",
      "Extracted year: 2014\n",
      "Error processing migration_flows_2014.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2015.xls\n",
      "Extracted year: 2015\n",
      "Error processing migration_flows_2015.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2016.xls\n",
      "Extracted year: 2016\n",
      "Error processing migration_flows_2016.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2017.xls\n",
      "Extracted year: 2017\n",
      "Error processing migration_flows_2017.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2021.xls\n",
      "Extracted year: 2021\n",
      "Error processing migration_flows_2021.xls: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2022.xlsx\n",
      "Extracted year: 2022\n",
      "Error processing migration_flows_2022.xlsx: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Processing file: migration_flows_2023.xlsx\n",
      "Extracted year: 2023\n",
      "Error processing migration_flows_2023.xlsx: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Created combined dataset with 13520 rows\n",
      "Saved results to migration_flows_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_migration_file(file_path):\n",
    "    try:\n",
    "        if file_path.startswith('~$'):  # Skip temporary Excel files\n",
    "            return None\n",
    "            \n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Get the year from the filename\n",
    "        year = int(file_path.split('_')[-1].split('.')[0])\n",
    "        print(f\"Extracted year: {year}\")\n",
    "        \n",
    "        if year >= 2010:\n",
    "            # Process 2010 and later files\n",
    "            # Drop the last 8 rows\n",
    "            df = df.iloc[:-8].reset_index(drop=True)\n",
    "            \n",
    "            # Find and drop MOE columns\n",
    "            moe_columns = []\n",
    "            for col in df.columns:\n",
    "                if isinstance(col, str) and 'MOE' in col:\n",
    "                    moe_columns.append(col)\n",
    "                elif df[col].astype(str).str.contains('MOE').any():\n",
    "                    moe_columns.append(col)\n",
    "            df = df.drop(columns=moe_columns)\n",
    "            \n",
    "            # Drop rows where all values are missing\n",
    "            df = df.dropna(how='all').reset_index(drop=True)\n",
    "            \n",
    "            # Drop first four rows\n",
    "            df = df.iloc[4:].reset_index(drop=True)\n",
    "            \n",
    "            # Set 'Stayed' in second column header\n",
    "            df.iloc[0, 1] = 'Stayed'\n",
    "            \n",
    "            # Delete specific rows\n",
    "            rows_to_drop = [i for i in [1, 2, 30, 31, 32] if i < len(df)]\n",
    "            df = df.drop(index=rows_to_drop).reset_index(drop=True)\n",
    "            \n",
    "            # Set \"Origin\" as first column header\n",
    "            df.iloc[0, 0] = \"Origin\"\n",
    "            \n",
    "            # Make the first row the column names\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.iloc[1:].reset_index(drop=True)\n",
    "            \n",
    "            # Drop any columns with 'nan' in the name\n",
    "            df = df.drop(columns=[col for col in df.columns if 'nan' in str(col).lower()])\n",
    "            \n",
    "            # Replace missing values where Origin matches column name\n",
    "            data = []\n",
    "            for idx, row in df.iterrows():\n",
    "                origin = row['Origin']\n",
    "                stayed_value = row.get('Stayed', None)\n",
    "                \n",
    "                for col in df.columns:\n",
    "                    if col not in ['Origin', 'Stayed']:\n",
    "                        value = row[col]\n",
    "                        # If this is the row where Origin matches the column name, use the Stayed value\n",
    "                        if str(origin) == str(col):\n",
    "                            value = stayed_value\n",
    "                        \n",
    "                        if pd.notna(value) and str(value).strip() != '':\n",
    "                            try:\n",
    "                                value = float(value)\n",
    "                                data.append({\n",
    "                                    'Origin': origin,\n",
    "                                    'Direction': col,\n",
    "                                    'Year': year,\n",
    "                                    'Population Change': value\n",
    "                                })\n",
    "                            except (ValueError, TypeError):\n",
    "                                print(f\"Warning: Could not convert value '{value}' to float\")\n",
    "                                continue\n",
    "            \n",
    "        else:\n",
    "            # Process pre-2010 files\n",
    "            # Drop the last 3 rows\n",
    "            df = df.iloc[:-3].reset_index(drop=True)\n",
    "            \n",
    "            # Find and drop MOE columns\n",
    "            moe_columns = []\n",
    "            for col in df.columns:\n",
    "                if isinstance(col, str) and 'MOE' in col:\n",
    "                    moe_columns.append(col)\n",
    "                elif df[col].astype(str).str.contains('MOE').any():\n",
    "                    moe_columns.append(col)\n",
    "            df = df.drop(columns=moe_columns)\n",
    "            \n",
    "            # Drop the first 5 rows\n",
    "            df = df.iloc[5:].reset_index(drop=True)\n",
    "            \n",
    "            # Drop rows where all values are missing\n",
    "            df = df.dropna(how='all').reset_index(drop=True)\n",
    "            \n",
    "            try:\n",
    "                # Drop specific rows (2 and 33-35)\n",
    "                df = df.drop(index=[1, 32, 33, 34]).reset_index(drop=True)\n",
    "            except KeyError as e:\n",
    "                print(f\"Warning: Some indices not found in {file_path}, continuing...\")\n",
    "            \n",
    "            # Make the first row first column equal to 0\n",
    "            df.iloc[0, 0] = 0\n",
    "            \n",
    "            # Set the first column as the index\n",
    "            df = df.set_index(df.columns[0])\n",
    "            \n",
    "            # Drop columns where the first row has missing values\n",
    "            df = df.loc[:, df.iloc[0].notna()]\n",
    "            \n",
    "            # Create flows dataframe\n",
    "            states = df.iloc[0].values\n",
    "            data = []\n",
    "            for i in range(1, len(df)):\n",
    "                for j in range(len(df.columns)):\n",
    "                    value = df.iloc[i, j]\n",
    "                    if pd.notna(value) and str(value).strip() != '':\n",
    "                        try:\n",
    "                            value = float(value)\n",
    "                            data.append({\n",
    "                                'Origin': states[j],\n",
    "                                'Direction': df.index[i],\n",
    "                                'Year': year,\n",
    "                                'Population Change': value\n",
    "                            })\n",
    "                        except (ValueError, TypeError):\n",
    "                            print(f\"Warning: Could not convert value '{value}' to float\")\n",
    "                            continue\n",
    "        \n",
    "        result_df = pd.DataFrame(data)\n",
    "        print(f\"Successfully processed {file_path}, created {len(result_df)} rows\")\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Get all Excel files in the directory\n",
    "excel_files = glob.glob('*.xls*')\n",
    "print(f\"Found {len(excel_files)} Excel files: {excel_files}\")\n",
    "\n",
    "# Process all files and store results in a list\n",
    "all_flows = []\n",
    "for file in excel_files:\n",
    "    flows = process_migration_file(file)\n",
    "    if flows is not None:\n",
    "        all_flows.append(flows)\n",
    "\n",
    "# Check if we have any processed data\n",
    "if len(all_flows) > 0:\n",
    "    # Combine all flows into one dataframe\n",
    "    combined_flows = pd.concat(all_flows, ignore_index=True)\n",
    "    print(f\"Created combined dataset with {len(combined_flows)} rows\")\n",
    "    \n",
    "    # Save the combined results\n",
    "    combined_flows.to_csv('migration_flows_combined.csv', index=False)\n",
    "    print(\"Saved results to migration_flows_combined.csv\")\n",
    "else:\n",
    "    print(\"No files were successfully processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table with row headers in column A, L, W, AH, AS, BD, BO, BZ, CK, CV, and DG, and column headers in rows 6 through 8 and 46 through 48.</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "      <th>Unnamed: 106</th>\n",
       "      <th>Unnamed: 107</th>\n",
       "      <th>Unnamed: 108</th>\n",
       "      <th>Unnamed: 109</th>\n",
       "      <th>Unnamed: 110</th>\n",
       "      <th>Unnamed: 111</th>\n",
       "      <th>Unnamed: 112</th>\n",
       "      <th>Unnamed: 113</th>\n",
       "      <th>Unnamed: 114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table.  Movers Within and Between States, the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Table.  Movers Within and Between States, the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset: 2005 American Community Survey 1-Year...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset: 2005 American Community Survey 1-Year...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universe: Population 1 year and over who moved...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Universe: Population 1 year and over who moved...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Current residence in --</td>\n",
       "      <td>Residence 1 year ago in --</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Current residence in --</td>\n",
       "      <td>Residence 1 year ago in --</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2275</td>\n",
       "      <td>2656</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>2197</td>\n",
       "      <td>942</td>\n",
       "      <td>992</td>\n",
       "      <td>762</td>\n",
       "      <td>6743</td>\n",
       "      <td>...</td>\n",
       "      <td>958</td>\n",
       "      <td>2390</td>\n",
       "      <td>1532</td>\n",
       "      <td>242</td>\n",
       "      <td>278</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>672491</td>\n",
       "      <td>19133</td>\n",
       "      <td>536</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>268</td>\n",
       "      <td>274</td>\n",
       "      <td>146</td>\n",
       "      <td>210</td>\n",
       "      <td>1229</td>\n",
       "      <td>1144</td>\n",
       "      <td>178</td>\n",
       "      <td>295</td>\n",
       "      <td>3353</td>\n",
       "      <td>...</td>\n",
       "      <td>514</td>\n",
       "      <td>781</td>\n",
       "      <td>561</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>35</td>\n",
       "      <td>66</td>\n",
       "      <td>61851</td>\n",
       "      <td>6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Footnotes:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>MOE - Margin of error based on 90% confidence ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOE - Margin of error based on 90% confidence ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Source: U.S. Census Bureau, 2005 American Comm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Source: U.S. Census Bureau, 2005 American Comm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Table with row headers in column A, L, W, AH, AS, BD, BO, BZ, CK, CV, and DG, and column headers in rows 6 through 8 and 46 through 48.  \\\n",
       "0   Table.  Movers Within and Between States, the ...                                                                                        \n",
       "1   Dataset: 2005 American Community Survey 1-Year...                                                                                        \n",
       "2   Universe: Population 1 year and over who moved...                                                                                        \n",
       "3                                                 NaN                                                                                        \n",
       "4                             Current residence in --                                                                                        \n",
       "..                                                ...                                                                                        \n",
       "72                                          Wisconsin                                                                                        \n",
       "73                                            Wyoming                                                                                        \n",
       "74                                         Footnotes:                                                                                        \n",
       "75  MOE - Margin of error based on 90% confidence ...                                                                                        \n",
       "76  Source: U.S. Census Bureau, 2005 American Comm...                                                                                        \n",
       "\n",
       "                    Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
       "0                          NaN        NaN        NaN        NaN        NaN   \n",
       "1                          NaN        NaN        NaN        NaN        NaN   \n",
       "2                          NaN        NaN        NaN        NaN        NaN   \n",
       "3                          NaN        NaN        NaN        NaN        NaN   \n",
       "4   Residence 1 year ago in --        NaN        NaN        NaN        NaN   \n",
       "..                         ...        ...        ...        ...        ...   \n",
       "72                        2275       2656        136        137       2197   \n",
       "73                         268        274        146        210       1229   \n",
       "74                         NaN        NaN        NaN        NaN        NaN   \n",
       "75                         NaN        NaN        NaN        NaN        NaN   \n",
       "76                         NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 105 Unnamed: 106  \\\n",
       "0         NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "1         NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "2         NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "3         NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "4         NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "..        ...        ...        ...        ...  ...          ...          ...   \n",
       "72        942        992        762       6743  ...          958         2390   \n",
       "73       1144        178        295       3353  ...          514          781   \n",
       "74        NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "75        NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "76        NaN        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "\n",
       "   Unnamed: 107 Unnamed: 108 Unnamed: 109  \\\n",
       "0           NaN          NaN          NaN   \n",
       "1           NaN          NaN          NaN   \n",
       "2           NaN          NaN          NaN   \n",
       "3           NaN          NaN          NaN   \n",
       "4           NaN          NaN          NaN   \n",
       "..          ...          ...          ...   \n",
       "72         1532          242          278   \n",
       "73          561           49           83   \n",
       "74          NaN          NaN          NaN   \n",
       "75          NaN          NaN          NaN   \n",
       "76          NaN          NaN          NaN   \n",
       "\n",
       "                                         Unnamed: 110  \\\n",
       "0   Table.  Movers Within and Between States, the ...   \n",
       "1   Dataset: 2005 American Community Survey 1-Year...   \n",
       "2   Universe: Population 1 year and over who moved...   \n",
       "3                                                 NaN   \n",
       "4                             Current residence in --   \n",
       "..                                                ...   \n",
       "72                                          Wisconsin   \n",
       "73                                            Wyoming   \n",
       "74                                                NaN   \n",
       "75  MOE - Margin of error based on 90% confidence ...   \n",
       "76  Source: U.S. Census Bureau, 2005 American Comm...   \n",
       "\n",
       "                  Unnamed: 111 Unnamed: 112 Unnamed: 113 Unnamed: 114  \n",
       "0                          NaN          NaN          NaN          NaN  \n",
       "1                          NaN          NaN          NaN          NaN  \n",
       "2                          NaN          NaN          NaN          NaN  \n",
       "3                          NaN          NaN          NaN          NaN  \n",
       "4   Residence 1 year ago in --          NaN          NaN          NaN  \n",
       "..                         ...          ...          ...          ...  \n",
       "72                      672491        19133          536          560  \n",
       "73                          35           66        61851         6023  \n",
       "74                         NaN          NaN          NaN          NaN  \n",
       "75                         NaN          NaN          NaN          NaN  \n",
       "76                         NaN          NaN          NaN          NaN  \n",
       "\n",
       "[77 rows x 115 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mig2005 = pd.read_excel('migration_flows_2005.xls')\n",
    "mig2005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 Excel files: ['migration_flows_2005.xls', 'migration_flows_2006.xls', 'migration_flows_2007.xls', 'migration_flows_2008.xls', 'migration_flows_2009.xls', 'migration_flows_2010.xls', 'migration_flows_2011.xls', 'migration_flows_2012.xls', 'migration_flows_2013.xls', 'migration_flows_2014.xls', 'migration_flows_2015.xls', 'migration_flows_2016.xls', 'migration_flows_2017.xls', 'migration_flows_2018.xls', 'migration_flows_2019.xls', 'migration_flows_2021.xls', 'migration_flows_2022.xlsx', 'migration_flows_2023.xlsx', '~$migration_flows_2023.xlsx']\n",
      "Processing file: migration_flows_2005.xls\n",
      "Extracted year: 2005\n",
      "Successfully processed migration_flows_2005.xls, created 2704 rows\n",
      "Processing file: migration_flows_2006.xls\n",
      "Extracted year: 2006\n",
      "Successfully processed migration_flows_2006.xls, created 2704 rows\n",
      "Processing file: migration_flows_2007.xls\n",
      "Extracted year: 2007\n",
      "Successfully processed migration_flows_2007.xls, created 2704 rows\n",
      "Processing file: migration_flows_2008.xls\n",
      "Extracted year: 2008\n",
      "Successfully processed migration_flows_2008.xls, created 2704 rows\n",
      "Processing file: migration_flows_2009.xls\n",
      "Extracted year: 2009\n",
      "Successfully processed migration_flows_2009.xls, created 2704 rows\n",
      "Processing file: migration_flows_2010.xls\n",
      "Extracted year: 2010\n",
      "Successfully processed migration_flows_2010.xls, created 2805 rows\n",
      "Processing file: migration_flows_2011.xls\n",
      "Extracted year: 2011\n",
      "Successfully processed migration_flows_2011.xls, created 2805 rows\n",
      "Processing file: migration_flows_2012.xls\n",
      "Extracted year: 2012\n",
      "Successfully processed migration_flows_2012.xls, created 2805 rows\n",
      "Processing file: migration_flows_2013.xls\n",
      "Extracted year: 2013\n",
      "Successfully processed migration_flows_2013.xls, created 2805 rows\n",
      "Processing file: migration_flows_2014.xls\n",
      "Extracted year: 2014\n",
      "Successfully processed migration_flows_2014.xls, created 2860 rows\n",
      "Processing file: migration_flows_2015.xls\n",
      "Extracted year: 2015\n",
      "Successfully processed migration_flows_2015.xls, created 2860 rows\n",
      "Processing file: migration_flows_2016.xls\n",
      "Extracted year: 2016\n",
      "Successfully processed migration_flows_2016.xls, created 2860 rows\n",
      "Processing file: migration_flows_2017.xls\n",
      "Extracted year: 2017\n",
      "Successfully processed migration_flows_2017.xls, created 2860 rows\n",
      "Processing file: migration_flows_2018.xls\n",
      "Extracted year: 2018\n",
      "Successfully processed migration_flows_2018.xls, created 2860 rows\n",
      "Processing file: migration_flows_2019.xls\n",
      "Extracted year: 2019\n",
      "Successfully processed migration_flows_2019.xls, created 2860 rows\n",
      "Processing file: migration_flows_2021.xls\n",
      "Extracted year: 2021\n",
      "Successfully processed migration_flows_2021.xls, created 2860 rows\n",
      "Processing file: migration_flows_2022.xlsx\n",
      "Extracted year: 2022\n",
      "Successfully processed migration_flows_2022.xlsx, created 2860 rows\n",
      "Processing file: migration_flows_2023.xlsx\n",
      "Extracted year: 2023\n",
      "Successfully processed migration_flows_2023.xlsx, created 2695 rows\n",
      "Created combined dataset with 50315 rows\n",
      "Saved results to migration_flows_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_migration_file(file_path):\n",
    "    try:\n",
    "        if file_path.startswith('~$'):  # Skip temporary Excel files\n",
    "            return None\n",
    "            \n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Get the year from the filename\n",
    "        year = int(file_path.split('_')[-1].split('.')[0])\n",
    "        print(f\"Extracted year: {year}\")\n",
    "        \n",
    "        # Drop the last rows (3 for pre-2010, 8 for 2010+)\n",
    "        if year >= 2010:\n",
    "            df = df.iloc[:-8].reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.iloc[:-3].reset_index(drop=True)\n",
    "        \n",
    "        # Find columns that contain 'MOE' as a value and drop them\n",
    "        moe_columns = []\n",
    "        for col in df.columns:\n",
    "            col_str = df[col].astype(str)\n",
    "            if col_str.str.contains('MOE').any():\n",
    "                moe_columns.append(col)\n",
    "        df = df.drop(columns=moe_columns)\n",
    "        \n",
    "        # Drop the first 5 rows\n",
    "        df = df.iloc[5:].reset_index(drop=True)\n",
    "        \n",
    "        # Drop rows where all values are missing\n",
    "        df = df.dropna(how='all').reset_index(drop=True)\n",
    "        \n",
    "        # Drop specific rows\n",
    "        try:\n",
    "            if year >= 2010:\n",
    "                df = df.drop(index=[1, 2, 30, 31, 32]).reset_index(drop=True)\n",
    "            else:\n",
    "                df = df.drop(index=[1, 32, 33, 34]).reset_index(drop=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        # Make the first row first column equal to 0\n",
    "        df.iloc[0, 0] = 0\n",
    "        \n",
    "        # Set the first column as the index\n",
    "        first_col = df.columns[0]\n",
    "        df = df.set_index(first_col)\n",
    "        \n",
    "        # Drop columns where the first row has missing values\n",
    "        df = df.loc[:, df.iloc[0].notna()]\n",
    "        \n",
    "        # Get states from the first row\n",
    "        states = df.iloc[0].values\n",
    "        \n",
    "        # Create flows dataframe\n",
    "        data = []\n",
    "        for i in range(1, len(df)):\n",
    "            for j in range(len(df.columns)):\n",
    "                value = df.iloc[i, j]\n",
    "                if pd.notna(value) and str(value).strip() != '':\n",
    "                    try:\n",
    "                        # Convert value to float, handling any commas\n",
    "                        clean_value = str(value).replace(',', '')\n",
    "                        float_value = float(clean_value)\n",
    "                        data.append({\n",
    "                            'Direction': states[j],\n",
    "                            'Origin': df.index[i],\n",
    "                            'Year': year,\n",
    "                            'Population Change': float_value\n",
    "                        })\n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "        \n",
    "        result_df = pd.DataFrame(data)\n",
    "        print(f\"Successfully processed {file_path}, created {len(result_df)} rows\")\n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Get all Excel files in the directory\n",
    "excel_files = glob.glob('*.xls*')\n",
    "print(f\"Found {len(excel_files)} Excel files: {excel_files}\")\n",
    "\n",
    "# Process all files and store results in a list\n",
    "all_flows = []\n",
    "for file in excel_files:\n",
    "    if not file.startswith('~$'):  # Skip temporary Excel files\n",
    "        flows = process_migration_file(file)\n",
    "        if flows is not None:\n",
    "            all_flows.append(flows)\n",
    "\n",
    "# Check if we have any processed data\n",
    "if len(all_flows) > 0:\n",
    "    # Combine all flows into one dataframe\n",
    "    combined_flows = pd.concat(all_flows, ignore_index=True)\n",
    "    print(f\"Created combined dataset with {len(combined_flows)} rows\")\n",
    "    \n",
    "    # Save the combined results\n",
    "    combined_flows.to_csv('migration_flows_combined.csv', index=False)\n",
    "    print(\"Saved results to migration_flows_combined.csv\")\n",
    "else:\n",
    "    print(\"No files were successfully processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_flows = pd.read_csv('migration_flows_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Direction</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Year</th>\n",
       "      <th>Population Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21935</th>\n",
       "      <td>Total</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>104102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21936</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21937</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>1077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21938</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>1108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21939</th>\n",
       "      <td>California</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>4918.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Direction   Origin  Year  Population Change\n",
       "21935       Total  Alabama  2013           104102.0\n",
       "21936      Alaska  Alabama  2013             1026.0\n",
       "21937     Arizona  Alabama  2013             1077.0\n",
       "21938    Arkansas  Alabama  2013             1108.0\n",
       "21939  California  Alabama  2013             4918.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_flows_2013 = combined_flows[combined_flows['Year'] == 2013]\n",
    "combined_flows_2013.head()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
